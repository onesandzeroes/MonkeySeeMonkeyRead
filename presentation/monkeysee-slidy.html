<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Grainger et al., 2012" />
  <title>Monkey See, Monkey Read: Orthographic Processing in Baboons (Papio papio)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">MathJax.Hub.Queue(["Typeset",MathJax.Hub]);</script>
  <script src="http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Monkey See, Monkey Read: Orthographic Processing in Baboons (Papio papio)</h1>
  <p class="author">
Grainger et al., 2012
  </p>
</div>
<div class="slide section level1">

<div class="figure">
<img src="figures/baboon.jpg" />
</div>
</div>
<div class="slide section level1">

<h2 id="word-recognition-and-lexical-decisions">Word Recognition and Lexical Decisions</h2>
<ul>
<li>Pretty simple task: present a word, ask the subject &quot;is this a word?&quot;</li>
<li>The &quot;no&quot; trials are nonwords: character strings that don't form real words</li>
</ul>
</div>
<div class="slide section level1">

<h2 id="levels-of-processing">Levels of processing</h2>
<div class="figure">
<img src="figures/interactive_activation.png" alt="Interactive activation model- McClelland and Rumelhart, 1981" /><p class="caption">Interactive activation model- McClelland and Rumelhart, 1981</p>
</div>
</div>
<div class="slide section level1">

<h2 id="does-the-lexical-decision-task-actually-require-this">Does the lexical decision task actually require this?</h2>
<ul>
<li><p>Do you need to access your internal representations to make decisions about:</p>
<ul>
<li>'COOK' and 'XUNQ'?</li>
<li>'LEAP' and 'RIST'?</li>
</ul></li>
</ul>
</div>
<div class="slide section level1">

<h2 id="teaching-monkeys-to-read">Teaching monkeys to read</h2>
<ul>
<li>6 socially-housed baboons with no prior exposure to written language</li>
<li>Starting testing sessions whenever they want.</li>
<li>Testing sessions are blocks of 100 trials: all monkeys did 40,000+ trials across the whole experiment</li>
</ul>
</div>
<div class="slide section level1">

<div class="figure">
<img src="figures/trial_outline.png" alt="Outline of each trial" /><p class="caption">Outline of each trial</p>
</div>
</div>
<div class="slide section level1">

<h2 id="testing-blocks">Testing blocks</h2>
<p>Each 100 trial block consists of:</p>
<ul>
<li>25 presentations of a new word</li>
<li>25 previously learned words</li>
<li>50 nonwords</li>
</ul>
<p>Words are considered learned when the monkey reaches 80% accuracy for that word within a block.</p>
<p>Note: for the baboons, a word is something they've seen before, a nonword is something new (or only seen very rarely).</p>
</div>
<div class="slide section level1">

<h2 id="example-words-and-nonwords">Example words and nonwords</h2>
<table>
<thead>
<tr class="header">
<th align="left">Words</th>
<th align="left">Nonwords</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">born</td>
<td align="left">sner</td>
</tr>
<tr class="even">
<td align="left">make</td>
<td align="left">onfs</td>
</tr>
<tr class="odd">
<td align="left">pane</td>
<td align="left">knec</td>
</tr>
<tr class="even">
<td align="left">week</td>
<td align="left">hilb</td>
</tr>
<tr class="odd">
<td align="left">limp</td>
<td align="left">grig</td>
</tr>
</tbody>
</table>
</div>
<div class="slide section level1">

<h2 id="the-overall-results">The Overall Results</h2>
<div class="figure">
<img src="figures/main_results.png" alt="Results graph from Grainger et al., 2012" /><p class="caption">Results graph from Grainger et al., 2012</p>
</div>
</div>
<div class="slide section level1">

<h2 id="some-preliminary-conclusions">Some preliminary conclusions</h2>
<ul>
<li>Monkeys are capable of learning the kinds of detailed visual information that is required for reading.</li>
<li>Human reading might be built on capacities that were already present in chimps, rather than abilities that were evolved more recently.</li>
</ul>
<blockquote>
<p>The primate brain might therefore be better prepared than previously thought to process printed words, hence facilitating the initial steps toward mastering one of the most complex of human skills: reading</p>
</blockquote>
</div>
<div class="slide section level1">

<div class="figure">
<img src="figures/new_words.png" alt="Responses to new words" /><p class="caption">Responses to new words</p>
</div>
</div>
<div class="slide section level1">

<h2 id="the-interesting-parts">The interesting parts</h2>
<ul>
<li>Towards the end, monkeys were more likely to classify novel real words as words.</li>
<li>Monkeys obviously aren't making decisions about these stimuli based on whether they're &quot;real English words&quot;</li>
<li>So, what sources of information <em>are</em> they using to make these decisions?</li>
</ul>
</div>
<div class="slide section level1">

<h2 id="word-like-words-and-nonword-like-nonwords">Word-like words and nonword-like nonwords</h2>
<p>Bigrams: <code>wasp -&gt; wa, as, sp</code></p>
<p>Bigram frequency: how often each pair of letters occurs in English words/text.</p>
<ul>
<li>Mean bigram frequency for words in the experiment: <span class="math">\(3.6 \times 10^{-4}\)</span></li>
<li>For nonwords: <span class="math">\(5.96 \times 10^{-5}\)</span></li>
</ul>
</div>
<div class="slide section level1">

<h2 id="statistical-structure-in-language">Statistical structure in language</h2>
<ul>
<li>Language is too complex and inconsistent to be easily captured by rules</li>
<li><em>But:</em> there are clear patterns and consistencies that appear when you examine large amounts of text.</li>
</ul>
</div>
<div class="slide section level1">

<div class="figure">
<img src="figures/moby_bigram_frequencies.png" />
</div>
</div>
<div class="slide section level1">

<h2 id="letter-probabilities">Letter probabilities</h2>
<p>From bigram counts, you can get the conditional probability of letters, given the letter that came before them:</p>
<p><span class="math">\(P(L_2|L_1) = \frac{\text{Count}(L_1, L_2)}{\text{Count}(L_1)}\)</span></p>
<p>And you can extend this approach up to trigrams, 4-grams, and 5-grams:</p>
<p><span class="math">\(P(L_3|L_1,L_2) = \frac{\text{Count}(L_1, L_2, L_3)}{\text{Count}(L_1, L_2)}\)</span></p>
</div>
<div class="slide section level1">

<div class="figure">
<img src="figures/codebreaking.png" alt="Codebreaking with bigram frequencies" /><p class="caption">Codebreaking with bigram frequencies</p>
</div>
<p>Diaconis, P. (2008). The Markov chain Monte Carlo revolution. Bulletin of the American Mathematical Society, 46(2), 179â€“205.</p>
</div>
<div class="slide section level1">

<div class="figure">
<img src="figures/dan_ngram_probs.png" alt="Trigram probabilities for the stimuli in the Grainger experiment" /><p class="caption">Trigram probabilities for the stimuli in the Grainger experiment</p>
</div>
</div>
<div class="slide section level1">

<h2 id="back-to-humans">Back to humans</h2>
<ul>
<li>Baboons seem to be able to build up some sort of memory for which letters follow which letters, and make lexical decisions based on this.</li>
<li>How do we know that humans aren't doing this?
<ul>
<li>Human studies deliberately use nonwords that are more similar in bigram frequency</li>
<li>But: even if you choose a good automated process for choosing nonwords, the nonwords can end up similar to each other, because they're being generated by the same process (see Keuleers and Brysbaert, 2011)</li>
</ul></li>
</ul>
</div>
<div class="slide section level1">

<h2 id="finally">Finally</h2>
<p><a href="http://www.youtube.com/watch?v=WTAl3x9PngI">Youtube video of the experimental setup</a></p>
</div>
</body>
</html>
